{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "os.environ['HADOOP_HOME'] = \"C:\\\\hadoop\"\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "jvm_options = (\n",
    "    \"--add-opens=java.base/java.lang=ALL-UNNAMED \"\n",
    "    \"--add-opens=java.base/java.lang.invoke=ALL-UNNAMED \"\n",
    "    \"--add-opens=java.base/java.lang.reflect=ALL-UNNAMED \"\n",
    "    \"--add-opens=java.base/java.io=ALL-UNNAMED \"\n",
    "    \"--add-opens=java.base/java.net=ALL-UNNAMED \"\n",
    "    \"--add-opens=java.base/java.nio=ALL-UNNAMED \"\n",
    "    \"--add-opens=java.base/java.util=ALL-UNNAMED \"\n",
    "    \"--add-opens=java.base/java.util.concurrent=ALL-UNNAMED \"\n",
    "    \"--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED \"\n",
    "    \"--add-opens=java.base/sun.nio.ch=ALL-UNNAMED \"\n",
    "    \"--add-opens=java.base/sun.nio.cs=ALL-UNNAMED \"\n",
    "    \"--add-opens=java.base/sun.security.action=ALL-UNNAMED \"\n",
    "    \"--add-opens=java.base/sun.util.calendar=ALL-UNNAMED \"\n",
    "    \"--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED\"\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ProyekSparkWindows\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", jvm_options) \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", jvm_options) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e7ce342-32fd-4c65-8b94-0f23a75dbe2a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Chapter 8: Machine Learning with SparkML Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e738fc6-d6c2-4dfc-82c7-f9bb18b087c7",
     "showTitle": true,
     "title": "Loading data"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+-------+---------+--------+-----------+---------+------------+-----------+----------+-----------+---------+\n",
      "| Id|MSSubClass|MSZoning|LotArea|LotConfig|BldgType|OverallCond|YearBuilt|YearRemodAdd|Exterior1st|BsmtFinSF2|TotalBsmtSF|SalePrice|\n",
      "+---+----------+--------+-------+---------+--------+-----------+---------+------------+-----------+----------+-----------+---------+\n",
      "|  0|        60|      RL|   8450|   Inside|    1Fam|          5|     2003|        2003|    VinylSd|         0|        856|   208500|\n",
      "|  1|        20|      RL|   9600|      FR2|    1Fam|          8|     1976|        1976|    MetalSd|         0|       1262|   181500|\n",
      "|  2|        60|      RL|  11250|   Inside|    1Fam|          5|     2001|        2002|    VinylSd|         0|        920|   223500|\n",
      "|  3|        70|      RL|   9550|   Corner|    1Fam|          5|     1915|        1970|    Wd Sdng|         0|        756|   140000|\n",
      "|  4|        60|      RL|  14260|      FR2|    1Fam|          5|     2000|        2000|    VinylSd|         0|       1145|   250000|\n",
      "+---+----------+--------+-------+---------+--------+-----------+---------+------------+-----------+----------+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Memuat Data (Loading data)\n",
    "\n",
    "# Read data in a Spark dataframe from dbfs path\n",
    "housing_data = spark.read.csv(\"HousePricePrediction.csv\", header=True)\n",
    "housing_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b639d64-39ee-4b84-80fd-2b24c7173a45",
     "showTitle": true,
     "title": "Print schema of the dataset"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[Id: string, MSSubClass: string, MSZoning: string, LotArea: string, LotConfig: string, BldgType: string, OverallCond: string, YearBuilt: string, YearRemodAdd: string, Exterior1st: string, BsmtFinSF2: string, TotalBsmtSF: string, SalePrice: string]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98e12c62-1b1e-49bf-b423-c116351a1a39",
     "showTitle": true,
     "title": "Count rows of data"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2919"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Membersihkan Data (Cleaning data)\n",
    "\n",
    "housing_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "144e1c48-1aa5-448e-a178-357ecab7f10a",
     "showTitle": true,
     "title": "Cleaning data - Removing na's"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with missing values\n",
    "cleaned_data = housing_data.dropna()\n",
    "cleaned_data.count()\n",
    "# cleaned_data.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd443ccb-dac4-4b27-b0e8-adb91b346e1e",
     "showTitle": true,
     "title": "Type casting string columns to long"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "cleaned_data = cleaned_data.withColumn(\"Id\", col(\"Id\").cast(\"long\")) \\\n",
    "                         .withColumn(\"MSSubClass\", col(\"MSSubClass\").cast(\"long\")) \\\n",
    "                         .withColumn(\"LotArea\", col(\"LotArea\").cast(\"long\")) \\\n",
    "                         .withColumn(\"OverallCond\", col(\"OverallCond\").cast(\"long\")) \\\n",
    "                         .withColumn(\"YearBuilt\", col(\"YearBuilt\").cast(\"long\")) \\\n",
    "                         .withColumn(\"YearRemodAdd\", col(\"YearRemodAdd\").cast(\"long\")) \\\n",
    "                         .withColumn(\"BsmtFinSF2\", col(\"BsmtFinSF2\").cast(\"long\")) \\\n",
    "                         .withColumn(\"TotalBsmtSF\", col(\"TotalBsmtSF\").cast(\"long\")) \\\n",
    "                         .withColumn(\"SalePrice\", col(\"SalePrice\").cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffa23a70-4725-48a6-8d38-02d1b1d4aeaf",
     "showTitle": true,
     "title": "Handling categorical variables"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+-------+---------+--------+-----------+---------+------------+-----------+----------+-----------+---------+-------------+\n",
      "| Id|MSSubClass|MSZoning|LotArea|LotConfig|BldgType|OverallCond|YearBuilt|YearRemodAdd|Exterior1st|BsmtFinSF2|TotalBsmtSF|SalePrice|MSZoningIndex|\n",
      "+---+----------+--------+-------+---------+--------+-----------+---------+------------+-----------+----------+-----------+---------+-------------+\n",
      "|  0|        60|      RL|   8450|   Inside|    1Fam|          5|     2003|        2003|    VinylSd|         0|        856|   208500|          0.0|\n",
      "|  1|        20|      RL|   9600|      FR2|    1Fam|          8|     1976|        1976|    MetalSd|         0|       1262|   181500|          0.0|\n",
      "|  2|        60|      RL|  11250|   Inside|    1Fam|          5|     2001|        2002|    VinylSd|         0|        920|   223500|          0.0|\n",
      "|  3|        70|      RL|   9550|   Corner|    1Fam|          5|     1915|        1970|    Wd Sdng|         0|        756|   140000|          0.0|\n",
      "|  4|        60|      RL|  14260|      FR2|    1Fam|          5|     2000|        2000|    VinylSd|         0|       1145|   250000|          0.0|\n",
      "|  5|        50|      RL|  14115|   Inside|    1Fam|          5|     1993|        1995|    VinylSd|         0|        796|   143000|          0.0|\n",
      "|  6|        20|      RL|  10084|   Inside|    1Fam|          5|     2004|        2005|    VinylSd|         0|       1686|   307000|          0.0|\n",
      "|  7|        60|      RL|  10382|   Corner|    1Fam|          6|     1973|        1973|    HdBoard|        32|       1107|   200000|          0.0|\n",
      "|  8|        50|      RM|   6120|   Inside|    1Fam|          5|     1931|        1950|    BrkFace|         0|        952|   129900|          1.0|\n",
      "|  9|       190|      RL|   7420|   Corner|  2fmCon|          6|     1939|        1950|    MetalSd|         0|        991|   118000|          0.0|\n",
      "| 10|        20|      RL|  11200|   Inside|    1Fam|          5|     1965|        1965|    HdBoard|         0|       1040|   129500|          0.0|\n",
      "| 11|        60|      RL|  11924|   Inside|    1Fam|          5|     2005|        2006|    WdShing|         0|       1175|   345000|          0.0|\n",
      "| 12|        20|      RL|  12968|   Inside|    1Fam|          6|     1962|        1962|    HdBoard|         0|        912|   144000|          0.0|\n",
      "| 13|        20|      RL|  10652|   Inside|    1Fam|          5|     2006|        2007|    VinylSd|         0|       1494|   279500|          0.0|\n",
      "| 14|        20|      RL|  10920|   Corner|    1Fam|          5|     1960|        1960|    MetalSd|         0|       1253|   157000|          0.0|\n",
      "| 15|        45|      RM|   6120|   Corner|    1Fam|          8|     1929|        2001|    Wd Sdng|         0|        832|   132000|          1.0|\n",
      "| 16|        20|      RL|  11241|  CulDSac|    1Fam|          7|     1970|        1970|    Wd Sdng|         0|       1004|   149000|          0.0|\n",
      "| 17|        90|      RL|  10791|   Inside|  Duplex|          5|     1967|        1967|    MetalSd|         0|          0|    90000|          0.0|\n",
      "| 18|        20|      RL|  13695|   Inside|    1Fam|          5|     2004|        2004|    VinylSd|         0|       1114|   159000|          0.0|\n",
      "| 19|        20|      RL|   7560|   Inside|    1Fam|          6|     1958|        1965|    BrkFace|         0|       1029|   139000|          0.0|\n",
      "+---+----------+--------+-------+---------+--------+-----------+---------+------------+-----------+----------+-----------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Menangani Variabel Kategorikal (Handling categorical variables)\n",
    "\n",
    "#import required libraries\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "mszoning_indexer = StringIndexer(inputCol=\"MSZoning\",\n",
    "outputCol=\"MSZoningIndex\")\n",
    "#Fits a model to the input dataset with optional parameters.\n",
    "df_mszoning = mszoning_indexer.fit(cleaned_data).transform(cleaned_data)\n",
    "df_mszoning.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ee612fc-7b29-4975-b050-3c38878818d5",
     "showTitle": true,
     "title": "Creating pipeline"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "mszoning_indexer = StringIndexer(inputCol=\"MSZoning\",\n",
    "outputCol=\"MSZoningIndex\")\n",
    "lotconfig_indexer = StringIndexer(inputCol=\"LotConfig\",\n",
    "outputCol=\"LotConfigIndex\")\n",
    "bldgtype_indexer = StringIndexer(inputCol=\"BldgType\",\n",
    "outputCol=\"BldgTypeIndex\")\n",
    "exterior1st_indexer = StringIndexer(inputCol=\"Exterior1st\",\n",
    "outputCol=\"Exterior1stIndex\")\n",
    "onehotencoder_mszoning_vector = OneHotEncoder(inputCol=\"MSZoningIndex\",\n",
    "                                              outputCol=\"MSZoningVector\")\n",
    "onehotencoder_lotconfig_vector = OneHotEncoder(inputCol=\"LotConfigIndex\", outputCol=\"LotConfigVector\")\n",
    "onehotencoder_bldgtype_vector = OneHotEncoder(inputCol=\"BldgTypeIndex\", outputCol=\"BldgTypeVector\")\n",
    "onehotencoder_exterior1st_vector = OneHotEncoder(inputCol=\"Exterior1stIndex\",\n",
    "outputCol=\"Exterior1stVector\")\n",
    "#Create pipeline and pass all stages\n",
    "pipeline = Pipeline(stages=[mszoning_indexer,\n",
    "                            lotconfig_indexer,\n",
    "                            bldgtype_indexer,\n",
    "                            exterior1st_indexer,\n",
    "                            onehotencoder_mszoning_vector,\n",
    "                            onehotencoder_lotconfig_vector,\n",
    "                            onehotencoder_bldgtype_vector,\n",
    "                            onehotencoder_exterior1st_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3557f09c-d86a-47e4-8965-4a54e03f80ea",
     "showTitle": true,
     "title": "Fit the pipeline to our cleaned dataset"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+-------+---------+--------+-----------+---------+------------+-----------+----------+-----------+---------+-------------+--------------+-------------+----------------+--------------+---------------+--------------+-----------------+\n",
      "| Id|MSSubClass|MSZoning|LotArea|LotConfig|BldgType|OverallCond|YearBuilt|YearRemodAdd|Exterior1st|BsmtFinSF2|TotalBsmtSF|SalePrice|MSZoningIndex|LotConfigIndex|BldgTypeIndex|Exterior1stIndex|MSZoningVector|LotConfigVector|BldgTypeVector|Exterior1stVector|\n",
      "+---+----------+--------+-------+---------+--------+-----------+---------+------------+-----------+----------+-----------+---------+-------------+--------------+-------------+----------------+--------------+---------------+--------------+-----------------+\n",
      "|  0|        60|      RL|   8450|   Inside|    1Fam|          5|     2003|        2003|    VinylSd|         0|        856|   208500|          0.0|           0.0|          0.0|             0.0| (4,[0],[1.0])|  (4,[0],[1.0])| (4,[0],[1.0])|   (14,[0],[1.0])|\n",
      "|  1|        20|      RL|   9600|      FR2|    1Fam|          8|     1976|        1976|    MetalSd|         0|       1262|   181500|          0.0|           3.0|          0.0|             2.0| (4,[0],[1.0])|  (4,[3],[1.0])| (4,[0],[1.0])|   (14,[2],[1.0])|\n",
      "|  2|        60|      RL|  11250|   Inside|    1Fam|          5|     2001|        2002|    VinylSd|         0|        920|   223500|          0.0|           0.0|          0.0|             0.0| (4,[0],[1.0])|  (4,[0],[1.0])| (4,[0],[1.0])|   (14,[0],[1.0])|\n",
      "|  3|        70|      RL|   9550|   Corner|    1Fam|          5|     1915|        1970|    Wd Sdng|         0|        756|   140000|          0.0|           1.0|          0.0|             3.0| (4,[0],[1.0])|  (4,[1],[1.0])| (4,[0],[1.0])|   (14,[3],[1.0])|\n",
      "|  4|        60|      RL|  14260|      FR2|    1Fam|          5|     2000|        2000|    VinylSd|         0|       1145|   250000|          0.0|           3.0|          0.0|             0.0| (4,[0],[1.0])|  (4,[3],[1.0])| (4,[0],[1.0])|   (14,[0],[1.0])|\n",
      "+---+----------+--------+-------+---------+--------+-----------+---------+------------+-----------+----------+-----------+---------+-------------+--------------+-------------+----------------+--------------+---------------+--------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformed = pipeline.fit(cleaned_data).transform(cleaned_data)\n",
    "df_transformed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07a9b83e-0a23-419f-8f28-ce8d413a9c09",
     "showTitle": true,
     "title": "Data cleanup"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSSubClass',\n",
       " 'LotArea',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'BsmtFinSF2',\n",
       " 'TotalBsmtSF',\n",
       " 'SalePrice',\n",
       " 'MSZoningIndex',\n",
       " 'LotConfigIndex',\n",
       " 'BldgTypeIndex',\n",
       " 'Exterior1stIndex',\n",
       " 'MSZoningVector',\n",
       " 'LotConfigVector',\n",
       " 'BldgTypeVector',\n",
       " 'Exterior1stVector']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pembersihan Data Lanjutan (Data cleanup)\n",
    "\n",
    "drop_column_list = [\"Id\", \"MSZoning\",\"LotConfig\",\"BldgType\", \"Exterior1st\"]\n",
    "df_dropped_cols = df_transformed.select([column for column in df_transformed.columns if column not in drop_column_list])\n",
    "df_dropped_cols.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4289e9b-a3d4-4d96-8106-0b30749d6995",
     "showTitle": true,
     "title": "Assembling the vector"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----------+---------+------------+----------+-----------+---------+-------------+--------------+-------------+----------------+--------------+---------------+--------------+-----------------+--------------------+\n",
      "|MSSubClass|LotArea|OverallCond|YearBuilt|YearRemodAdd|BsmtFinSF2|TotalBsmtSF|SalePrice|MSZoningIndex|LotConfigIndex|BldgTypeIndex|Exterior1stIndex|MSZoningVector|LotConfigVector|BldgTypeVector|Exterior1stVector|            features|\n",
      "+----------+-------+-----------+---------+------------+----------+-----------+---------+-------------+--------------+-------------+----------------+--------------+---------------+--------------+-----------------+--------------------+\n",
      "|        60|   8450|          5|     2003|        2003|         0|        856|   208500|          0.0|           0.0|          0.0|             0.0| (4,[0],[1.0])|  (4,[0],[1.0])| (4,[0],[1.0])|   (14,[0],[1.0])|(37,[0,1,2,3,4,6,...|\n",
      "|        20|   9600|          8|     1976|        1976|         0|       1262|   181500|          0.0|           3.0|          0.0|             2.0| (4,[0],[1.0])|  (4,[3],[1.0])| (4,[0],[1.0])|   (14,[2],[1.0])|(37,[0,1,2,3,4,6,...|\n",
      "|        60|  11250|          5|     2001|        2002|         0|        920|   223500|          0.0|           0.0|          0.0|             0.0| (4,[0],[1.0])|  (4,[0],[1.0])| (4,[0],[1.0])|   (14,[0],[1.0])|(37,[0,1,2,3,4,6,...|\n",
      "+----------+-------+-----------+---------+------------+----------+-----------+---------+-------------+--------------+-------------+----------------+--------------+---------------+--------------+-----------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Merakit Vektor (Assembling the vector)\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "#Assembling features\n",
    "feature_assembly = VectorAssembler(inputCols = ['MSSubClass',\n",
    " 'LotArea',\n",
    " 'OverallCond',\n",
    " 'YearBuilt',\n",
    " 'YearRemodAdd',\n",
    " 'BsmtFinSF2',\n",
    " 'TotalBsmtSF',\n",
    " 'MSZoningIndex',\n",
    " 'LotConfigIndex',\n",
    " 'BldgTypeIndex',\n",
    " 'Exterior1stIndex',\n",
    " 'MSZoningVector',\n",
    " 'LotConfigVector',\n",
    " 'BldgTypeVector',\n",
    " 'Exterior1stVector'], outputCol = 'features')\n",
    "output = feature_assembly.transform(df_dropped_cols)\n",
    "output.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a2a26e8-ca58-492f-a561-89254613d31d",
     "showTitle": true,
     "title": "Feature scaling"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----------+---------+------------+----------+-----------+---------+-------------+--------------+-------------+----------------+--------------+---------------+--------------+-----------------+--------------------+--------------------+\n",
      "|MSSubClass|LotArea|OverallCond|YearBuilt|YearRemodAdd|BsmtFinSF2|TotalBsmtSF|SalePrice|MSZoningIndex|LotConfigIndex|BldgTypeIndex|Exterior1stIndex|MSZoningVector|LotConfigVector|BldgTypeVector|Exterior1stVector|            features|      scaledFeatures|\n",
      "+----------+-------+-----------+---------+------------+----------+-----------+---------+-------------+--------------+-------------+----------------+--------------+---------------+--------------+-----------------+--------------------+--------------------+\n",
      "|        60|   8450|          5|     2003|        2003|         0|        856|   208500|          0.0|           0.0|          0.0|             0.0| (4,[0],[1.0])|  (4,[0],[1.0])| (4,[0],[1.0])|   (14,[0],[1.0])|(37,[0,1,2,3,4,6,...|(37,[0,1,2,3,4,6,...|\n",
      "|        20|   9600|          8|     1976|        1976|         0|       1262|   181500|          0.0|           3.0|          0.0|             2.0| (4,[0],[1.0])|  (4,[3],[1.0])| (4,[0],[1.0])|   (14,[2],[1.0])|(37,[0,1,2,3,4,6,...|(37,[0,1,2,3,4,6,...|\n",
      "|        60|  11250|          5|     2001|        2002|         0|        920|   223500|          0.0|           0.0|          0.0|             0.0| (4,[0],[1.0])|  (4,[0],[1.0])| (4,[0],[1.0])|   (14,[0],[1.0])|(37,[0,1,2,3,4,6,...|(37,[0,1,2,3,4,6,...|\n",
      "+----------+-------+-----------+---------+------------+----------+-----------+---------+-------------+--------------+-------------+----------------+--------------+---------------+--------------+-----------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Normalizing the features\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "# Compute summary statistics by fitting the StandardScaler\n",
    "scalerModel = scaler.fit(output)\n",
    "\n",
    "# Normalize each feature to have unit standard deviation.\n",
    "scaledOutput = scalerModel.transform(output)\n",
    "scaledOutput.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "affe1279-1105-4d95-9a64-3362f1560d18",
     "showTitle": true,
     "title": "Select scaled features and target column"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|SalePrice|      scaledFeatures|\n",
      "+---------+--------------------+\n",
      "|   208500|(37,[0,1,2,3,4,6,...|\n",
      "|   181500|(37,[0,1,2,3,4,6,...|\n",
      "|   223500|(37,[0,1,2,3,4,6,...|\n",
      "+---------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Selecting input and output column from output\n",
    "df_model_final = scaledOutput.select(['SalePrice', 'scaledFeatures'])\n",
    "df_model_final.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "523f0000-634f-413f-b7a8-bece0a24b16c",
     "showTitle": true,
     "title": "Splitting the data"
    }
   },
   "outputs": [],
   "source": [
    "# Memisahkan Data (Splitting the data)\n",
    "\n",
    "#test train split\n",
    "df_train, df_test = df_model_final.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcd515d5-c254-4c7e-b41e-349fc7ce4f7b",
     "showTitle": true,
     "title": "Model training"
    }
   },
   "outputs": [],
   "source": [
    "# Pelatihan Model (Model training)\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "# Instantiate the linear regression model\n",
    "regressor = LinearRegression(featuresCol = 'scaledFeatures', labelCol = 'SalePrice')\n",
    "# Fit the model on the training data\n",
    "regressor = regressor.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da2bf8a8-8a3f-45a8-abd4-3382a2842ff4",
     "showTitle": true,
     "title": "Model evaluation"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train MSE for the model is: 31526.707719\n",
      "The train r2 for the model is: 0.610512\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi Model (Model evaluation)\n",
    "\n",
    "#MSE for the train data\n",
    "\n",
    "pred_results = regressor.evaluate(df_train)\n",
    "print(\"The train MSE for the model is: %2f\"% pred_results.meanAbsoluteError)\n",
    "print(\"The train r2 for the model is: %2f\"% pred_results.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff446fff-13f5-4274-aa08-11db5cdbdaf0",
     "showTitle": true,
     "title": "Checking test dataâ€™s performance"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test MSE for the model is: 33957.332360\n",
      "The test r2 for the model is: 0.623924\n"
     ]
    }
   ],
   "source": [
    "#Checking test performance\n",
    "pred_results = regressor.evaluate(df_test)\n",
    "print(\"The test MSE for the model is: %2f\"% pred_results.meanAbsoluteError)\n",
    "print(\"The test r2 for the model is: %2f\"% pred_results.r2)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 969987236417588,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Chapter 8 Code",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
